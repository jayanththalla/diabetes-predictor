<!DOCTYPE html>
<html>
  <head>
    <title>Random Forest - Diabetes Diagnosis</title>
    <link rel="stylesheet" type="text/css" href="/static/style.css" />
    <script src="https://cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script>
    <script src="static/particle.js" defer></script>
  </head>
  <body>
    <div
      id="particles-js"
      style="position: absolute; width: 100%; height: 100%"
    ></div>
    <div class="content" style="position: relative; z-index: 1">
      <h1>Random Forest</h1>
      <p>
        Random Forest is an ensemble learning method that constructs a multitude
        of decision trees during training and outputs the mode of the classes
        (for classification) or the average prediction (for regression) of the
        individual trees. Here's how it works:<br /><br />
        Ensemble of Decision Trees: Random Forest builds multiple decision
        trees, each trained on a random subset of the training data and using a
        random subset of the features. This randomness helps in reducing
        overfitting and improving robustness compared to individual decision
        trees.<br /><br />
        Bootstrap Aggregation (Bagging): Each tree in the forest is grown using
        a technique called bootstrap sampling, where random samples with
        replacement are drawn from the training set. This ensures diversity
        among the trees.<br /><br />
        Feature Randomness: At each node of a decision tree, only a subset of
        features is considered for splitting. This further increases diversity
        and prevents certain features from dominating the decision-making
        process.<br /><br />
        Prediction: For classification tasks, the final prediction is determined
        by a majority vote of the predictions from each tree. For regression
        tasks, it averages the predictions from all trees.<br /><br />
        Random Forests are robust against overfitting, perform well with
        high-dimensional data, and are less sensitive to outliers compared to
        individual decision trees. They are widely used in various fields such
        as finance, healthcare, and bioinformatics due to their ability to
        handle complex datasets and provide reliable predictions. However,
        training a large number of trees can be computationally expensive, and
        interpreting the model can be more challenging compared to simpler
        models like decision trees.
      </p>
      <a href="{{ url_for('diagnosis', model_name='random_forest') }}"
        >Diagnose Your Health</a
      >
    </div>
  </body>
</html>
